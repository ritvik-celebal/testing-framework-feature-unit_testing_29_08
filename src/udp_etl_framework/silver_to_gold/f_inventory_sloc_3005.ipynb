{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af237230-9538-49df-8f70-d12e50c07a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utils/common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d78542c-e72f-4b9a-a3be-975d2587d9a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"environment\", \"\", \"\")\n",
    "dbutils.widgets.text(\"target_dataset\", \"VCM_DWH_PRD\")\n",
    "dbutils.widgets.text(\"target_table\", \"f_inventory_sloc_3005\")\n",
    "dbutils.widgets.text(\"metadata_schema\", \"udp_wcm_metadata_dev\")\n",
    "dbutils.widgets.text(\n",
    "    \"dependency_table\",\"VCM_STG_INF.SAP_VCDMMIM01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7d90cb6-e4b9-4b8f-8d6f-d855690686ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"environment\", \"\", \"\")\n",
    "environment = dbutils.widgets.get(\"environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd32870-9b80-4dfd-9b0b-e7170536a5e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = settings[environment]['catalog_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ab46f74-9358-4545-a303-4be476095818",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "environment = dbutils.widgets.get(\"environment\")\n",
    "target_dataset = dbutils.widgets.get(\"target_dataset\")\n",
    "target_table = dbutils.widgets.get(\"target_table\")\n",
    "metadata_schema = dbutils.widgets.get(\"metadata_schema\")\n",
    "dependency_table = dbutils.widgets.get(\"dependency_table\")\n",
    "dependency_table = [x.strip().upper() for x in dependency_table.split(\",\")]\n",
    "dependency_table = \"'\" + \"','\".join(dependency_table) + \"'\"\n",
    "\n",
    "print(f\"environment: {environment}\")\n",
    "print(f\"target_dataset: {target_dataset}\")\n",
    "print(f\"target_table: {target_table}\")\n",
    "print(f\"catalog_name: {catalog_name}\")\n",
    "print(f\"metadata_schema: {metadata_schema}\")\n",
    "print(f\"dependency_table: {dependency_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06f4a0e3-80eb-4067-bd2d-ef0e492d62aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../common/common_etl_load\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce83b8a0-6ca5-442d-87d1-1289f1200e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {catalog_name}.udp_wcm_gold_vcm_dwh.f_inventory_sloc_3005\n",
    "(\n",
    "  hash_id BIGINT,\n",
    "  calday DATE,\n",
    "  store_id STRING,\n",
    "  product_id STRING,\n",
    "  closing_stock_quantity FLOAT\n",
    ") \n",
    "TBLPROPERTIES (\n",
    "  'DELTA.AUTOOPTIMIZE.OPTIMIZEWRITE' = 'TRUE',\n",
    "  'DELTA.AUTOOPTIMIZE.AUTOCOMPACT' = 'TRUE'\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c85e57e1-2f2e-4419-b26b-4eb3ef4f5612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW temp_{target_table} AS\n",
    "WITH table_date AS \n",
    "(\n",
    "    SELECT col AS date_gen\n",
    "    FROM EXPLODE(SEQUENCE(DATE {START_DATE}, DATE {END_DATE})) AS date_gen\n",
    "    WHERE col <= CURRENT_DATE() \n",
    ")\n",
    "SELECT \n",
    "* EXCEPT(rn, date_from, date_to) \n",
    "FROM (\n",
    "    SELECT\n",
    "        farm_fingerprint(CONCAT(\n",
    "            IFNULL(CAST(date_gen AS STRING), \"\"), \n",
    "            IFNULL(CAST(store_id AS STRING), \"\"), \n",
    "            IFNULL(CAST(product_id AS STRING), \"\")\n",
    "        )) AS hash_id,\n",
    "        date_gen AS calday,\n",
    "        store_id,\n",
    "        product_id,\n",
    "        closing_stock_quantity,\n",
    "        ROW_NUMBER() OVER (PARTITION BY store_id, product_id, CAST(closing_stock_quantity AS BIGINT) ORDER BY date_gen ASC) AS rn,\n",
    "        date_from,\n",
    "        DATE_SUB(IFNULL(date_to, '2400-01-01'), 1) AS date_to\n",
    "    FROM table_date \n",
    "    INNER JOIN \n",
    "    (\n",
    "        SELECT\n",
    "            calday,\n",
    "            store_id,\n",
    "            product_id,\n",
    "            ROUND(SUM(closing_stock_quantity) OVER (PARTITION BY store_id, product_id ORDER BY calday ASC), 3) AS closing_stock_quantity,\n",
    "            calday AS date_from,\n",
    "            LEAD(calday) OVER (PARTITION BY store_id, product_id ORDER BY calday ASC) AS date_to\n",
    "        FROM \n",
    "        (\n",
    "            SELECT  \n",
    "                calday, store_id, product_id, closing_stock_quantity \n",
    "            FROM {catalog_name}.udp_wcm_gold_vcm_dwh.f_staging_inventory_sloc_3005  \n",
    "            WHERE calday >= {START_DATE} AND calday <= {END_DATE} AND calday <= CURRENT_DATE()\n",
    "            UNION ALL\n",
    "            SELECT \n",
    "                calday, store_id, product_id, closing_stock_quantity \n",
    "            FROM {catalog_name}.udp_wcm_gold_vcm_dwh.f_inventory_sloc_3005 \n",
    "            WHERE calday = DATE_SUB({START_DATE}, 1)\n",
    "        ) a\n",
    "    ) i\n",
    "    ON date_gen >= calday AND (date_gen < date_to OR date_to IS NULL)\n",
    ") a \n",
    "WHERE closing_stock_quantity != 0 OR rn = 1\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "226f90c0-dfae-42bc-b21c-889186a80e20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if CALDAY_IN_STR != \"\":\n",
    "    # Get the calday list string from temp table\n",
    "    calday_query = f\"\"\"\n",
    "    SELECT\n",
    "        CONCAT(\"'\", CONCAT_WS(\"','\", COLLECT_SET(CAST(TO_DATE(calday, 'yyyy-MM-dd') AS STRING))), \"'\") AS calday_in_str\n",
    "    FROM temp_{target_table}\n",
    "    \"\"\"\n",
    "\n",
    "    calday_df = spark.sql(calday_query)\n",
    "    calday_in_str = calday_df.collect()[0][0]\n",
    "\n",
    "    # Only run DELETE if the string is non-empty\n",
    "    if calday_in_str.strip(\"'\"):  # checks if there's any date inside the quotes\n",
    "        spark.sql(\n",
    "            f\"\"\"\n",
    "        DELETE FROM {catalog_name}.udp_wcm_gold_vcm_dwh.f_inventory_sloc_3005\n",
    "        WHERE calday IN ({calday_in_str})\n",
    "        \"\"\"\n",
    "        ).display()\n",
    "    else:\n",
    "        print(\"no valid calday's found to delete.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"temp_{target_table} could't be created as no valid calday's found In common-etl so {catalog_name}.udp_wcm_gold_vcm_dwh.f_inventory_sloc_3005 can't be deleted using calday's from temp_a_billcnt_store\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49fd3de1-732d-4197-b6b7-872a6b14c5d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if CALDAY_IN_STR != \"\":\n",
    "    # Insert rows from temp table into main table\n",
    "    INSERT_ROW = \", \".join(\n",
    "        spark.table(f\"{catalog_name}.udp_wcm_gold_vcm_dwh.f_inventory_sloc_3005\").columns\n",
    "    )\n",
    "    spark.sql(\n",
    "        f\"\"\"\n",
    "        INSERT INTO {catalog_name}.udp_wcm_gold_vcm_dwh.f_inventory_sloc_3005 ({INSERT_ROW})\n",
    "        SELECT {INSERT_ROW} FROM temp_{target_table}\n",
    "    \"\"\"\n",
    "    ).display()\n",
    "else:\n",
    "    print(\n",
    "        f\"temp_{target_table} could't be created as no valid calday's found In common-etl so {catalog_name}.udp_wcm_gold_vcm_dwh.f_inventory_sloc_3005 can't be inserted using calday's from temp_{target_table}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7b0ad2a-db99-4d75-9dfc-4a9858b4b642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "DROP TABLE IF EXISTS temp_{target_table}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6605737921177031,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "f_inventory_sloc_3005",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
