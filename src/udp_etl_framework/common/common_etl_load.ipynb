{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f498cc2-9e25-4b04-91a6-7505dcad7be0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(proc_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93ba0103-9fc5-4a12-8e30-86773c6649df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Common_Etl_Load:\n",
    "    def __init__(self, target_dataset, catalog_name, target_table, metadata_schema, dependency_table):\n",
    "        self.target_dataset = target_dataset.upper()\n",
    "        self.catalog_name = catalog_name\n",
    "        self.target_table = target_table.upper()\n",
    "        self.metadata_schema = metadata_schema\n",
    "        self.dependency_table = dependency_table\n",
    "\n",
    "    def create_vw_table_dependencies(self):\n",
    "        query = f\"\"\"\n",
    "        CREATE OR REPLACE TEMP VIEW {self.target_table}_DEPENDENCIES AS\n",
    "        WITH ETL_LOG_DEPENDENCIES AS (\n",
    "            SELECT\n",
    "                DEPENDENCY_TABLE,\n",
    "                MAX(ETL_TO_TS) AS LATEST_ETL_TS\n",
    "            FROM\n",
    "                {self.catalog_name}.{metadata_schema}.ETL_LOG_DEPENDENCIES\n",
    "            WHERE\n",
    "                concat_ws('.', DATASET_AFFECT, TABLE_AFFECT) = '{self.target_dataset}.{self.target_table}'\n",
    "                AND proc_date = date('{proc_date}')\n",
    "            GROUP BY\n",
    "                DEPENDENCY_TABLE\n",
    "        )\n",
    "        SELECT\n",
    "           max(PROC_DATE) as proc_date,\n",
    "            \"{self.target_dataset}\" AS DATASET_AFFECT,\n",
    "            \"{self.target_table}\" AS TABLE_AFFECT,\n",
    "            concat_ws('.', A.DATASET_AFFECT, A.TABLE_AFFECT) AS DEPENDENCY_TABLE,\n",
    "            CASE\n",
    "                WHEN A1.DEPENDENCY_TABLE IS NULL THEN MIN(A.PROC_DATE)\n",
    "                ELSE MIN(IF(A.PROC_DATE > A1.LATEST_ETL_TS, A.PROC_DATE, NULL))\n",
    "            END AS ETL_FROM_TS,\n",
    "            CASE\n",
    "                WHEN A1.DEPENDENCY_TABLE IS NULL THEN MAX(A.PROC_DATE)\n",
    "                ELSE MAX(IF(A.PROC_DATE > A1.LATEST_ETL_TS, A.PROC_DATE, NULL))\n",
    "            END AS ETL_TO_TS\n",
    "        FROM\n",
    "            {self.catalog_name}.{metadata_schema}.ETL_DELTA_TABLE A\n",
    "            INNER JOIN ETL_LOG_DEPENDENCIES A1\n",
    "            ON concat_ws('.', A.DATASET_AFFECT, A.TABLE_AFFECT) = (A1.DEPENDENCY_TABLE)\n",
    "        WHERE A.PROC_DATE = date_add(DATE('{proc_date}'), 1)\n",
    "        GROUP BY\n",
    "            A.DATASET_AFFECT,\n",
    "            A.TABLE_AFFECT,\n",
    "            A1.DEPENDENCY_TABLE\n",
    "        \"\"\"\n",
    "        spark.sql(query)\n",
    "        \n",
    "        print(f\"Debug: {self.target_table}_dependencies\")\n",
    "        print(query)\n",
    "    \n",
    "    print(\"execution started not executed\")\n",
    "\n",
    "\n",
    "    def create_fn_clean_caldayinstr(self):\n",
    "        spark.sql(\n",
    "            f\"\"\"\n",
    "        CREATE FUNCTION IF NOT EXISTS {self.catalog_name}.default.fn_CLEAN_CALDAYINSTR(CALDAYINSTR STRING)\n",
    "            RETURNS STRING\n",
    "            LANGUAGE SQL\n",
    "            DETERMINISTIC\n",
    "            RETURN\n",
    "                (\n",
    "                SELECT\n",
    "                    array_join(\n",
    "                    array_distinct(\n",
    "                        filter(\n",
    "                        transform(split(CALDAYINSTR, ','), x -> trim(x)),\n",
    "                        x -> x IS NOT NULL\n",
    "                        AND x != ''\n",
    "                        AND try_cast(trim(replace(replace(replace(x, '\"', ''), \"'\", \"\"), \" \", \"\")) AS DATE) BETWEEN\n",
    "                            date_trunc('year', add_months(current_date(), -12))\n",
    "                        AND\n",
    "                            current_date()\n",
    "                        )\n",
    "                    ),\n",
    "                    ','\n",
    "                    )\n",
    "                )\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    print(\"function not executed\")\n",
    "    def get_all_static_values(self):\n",
    "        (\n",
    "            START_DATE,\n",
    "            END_DATE,\n",
    "            START_DATE_D,\n",
    "            END_DATE_D,\n",
    "            TABLE_AFFECT_COUNT,\n",
    "            TABLE_ETL,\n",
    "            CALDAY_IN_STR,\n",
    "        ) = spark.sql(\n",
    "            f\"\"\"\n",
    "        SELECT\n",
    "            \"'\" || cast(min(START_DATE) as STRING) || \"'\" as START_DATE,\n",
    "            \"'\" || cast(max(END_DATE) as STRING) || \"'\" as END_DATE,\n",
    "            CASE\n",
    "                WHEN\n",
    "                MIN(a.START_DATE) < date_trunc('year', add_months(current_date(), -12))\n",
    "                THEN\n",
    "                date_trunc('year', add_months(current_date(), -12))\n",
    "                ELSE MIN(a.START_DATE)\n",
    "            END as START_DATE_D,\n",
    "            MAX(a.END_DATE) as END_DATE_D,\n",
    "            COUNT(DISTINCT a1.DEPENDENCY_TABLE) as TABLE_AFFECT_COUNT,\n",
    "            array_join(collect_set(a1.DEPENDENCY_TABLE), ',') as TABLE_ETL,\n",
    "            {self.catalog_name}.default.fn_CLEAN_CALDAYINSTR(array_join((collect_set(a.CALDAY_IN_STR)), ',')) as CALDAY_IN_STR\n",
    "        FROM\n",
    "            {self.catalog_name}.{self.metadata_schema}.ETL_DELTA_TABLE a\n",
    "            JOIN {self.target_table}_DEPENDENCIES a1\n",
    "            ON concat(a.DATASET_AFFECT, '.', a.TABLE_AFFECT) = a1.DEPENDENCY_TABLE\n",
    "        WHERE\n",
    "            a.PROC_DATE BETWEEN a1.ETL_FROM_TS AND a1.ETL_TO_TS\n",
    "        \"\"\"\n",
    "        ).head()\n",
    "\n",
    "        \n",
    "        print(f\"\\nDebug: static Datasets\")\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        SELECT\n",
    "            \"'\" || cast(min(START_DATE) as STRING) || \"'\" as START_DATE,\n",
    "            \"'\" || cast(max(END_DATE) as STRING) || \"'\" as END_DATE,\n",
    "            CASE\n",
    "                WHEN\n",
    "                MIN(a.START_DATE) < date_trunc('year', add_months(current_date(), -12))\n",
    "                THEN\n",
    "                date_trunc('year', add_months(current_date(), -12))\n",
    "                ELSE MIN(a.START_DATE)\n",
    "            END as START_DATE_D,\n",
    "            MAX(a.END_DATE) as END_DATE_D,\n",
    "            COUNT(DISTINCT a1.DEPENDENCY_TABLE) as TABLE_AFFECT_COUNT,\n",
    "            array_join(collect_set(a1.DEPENDENCY_TABLE), ',') as TABLE_ETL,\n",
    "            {self.catalog_name}.default.fn_CLEAN_CALDAYINSTR(array_join((collect_set(trim(a.CALDAY_IN_STR))), ',')) as CALDAY_IN_STR\n",
    "        FROM\n",
    "            {self.catalog_name}.{self.metadata_schema}.ETL_DELTA_TABLE a\n",
    "            JOIN {self.target_table}_DEPENDENCIES a1\n",
    "            ON concat(a.DATASET_AFFECT, '.', a.TABLE_AFFECT) = a1.DEPENDENCY_TABLE\n",
    "        WHERE\n",
    "            a.PROC_DATE BETWEEN a1.ETL_FROM_TS AND a1.ETL_TO_TS\n",
    "        \"\"\"\n",
    "        )\n",
    "        \n",
    "\n",
    "        return (\n",
    "            START_DATE,\n",
    "            END_DATE,\n",
    "            START_DATE_D,\n",
    "            END_DATE_D,\n",
    "            TABLE_AFFECT_COUNT,\n",
    "            TABLE_ETL,\n",
    "            CALDAY_IN_STR,\n",
    "        )\n",
    "\n",
    "    def __main__(self):\n",
    "        self.create_fn_clean_caldayinstr() \n",
    "        # <comnmenting at the moment as the function creation multilpe time causing access issues>\n",
    "        self.create_vw_table_dependencies()\n",
    "        return self.get_all_static_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e006e58a-7a2d-458b-a605-973749dd8a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(target_dataset)\n",
    "print(target_table)\n",
    "print(metadata_schema)\n",
    "print(dependency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "638f9cdc-d109-4f71-982e-49511c2a42b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "common_etl_load = Common_Etl_Load(\n",
    "    target_dataset=target_dataset,\n",
    "    catalog_name=catalog_name,\n",
    "    target_table=target_table,\n",
    "    metadata_schema=metadata_schema,\n",
    "    dependency_table=dependency_table\n",
    ")\n",
    "\n",
    "(\n",
    "    START_DATE,\n",
    "    END_DATE,\n",
    "    START_DATE_D,\n",
    "    END_DATE_D,\n",
    "    TABLE_AFFECT_COUNT,\n",
    "    TABLE_ETL,\n",
    "    CALDAY_IN_STR\n",
    ") = common_etl_load.__main__()\n",
    "\n",
    "print(f\"START_DATE: {START_DATE}\")\n",
    "print(f\"END_DATE: {END_DATE}\")\n",
    "print(f\"START_DATE_D: {START_DATE_D}\")\n",
    "print(f\"END_DATE_D: {END_DATE_D}\")\n",
    "print(f\"TABLE_AFFECT_COUNT: {TABLE_AFFECT_COUNT}\")\n",
    "print(f\"TABLE_ETL: {TABLE_ETL}\")\n",
    "print(f\"CALDAY_IN_STR: {CALDAY_IN_STR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f21fb4f-1b8b-44a6-a98e-a2387fd2a137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6410538414248156,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "common_etl_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
